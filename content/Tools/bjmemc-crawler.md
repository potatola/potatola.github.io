Title: 爬取加密的silverlight网站数据 
Date: 2015-12-17 21:48:08
Tags: crawler
Slug: bjmemc-crawler


很久之前帮妹子写了个小脚本爬"[北京空气质量](http://zx.bjmemc.com.cn/)"网站上的空气数据. 当时用wireshark抓包分析请求和返回数据格式, 用python发个post很容易就把数据爬下来了. 但是用了一阵子突然全都变成了乱码, 发现网站数据居然加密了, 对这方面实在不了解只好作罢, 苦了妹子和实验室同学天天手抄数据(还好当时只需要一天记录一次).

最近那边老师要每小时数据了, 这个实在没办法手抄, 于是咬咬牙各种百度google, 再次解决了数据加密问题, 又可以愉快地爬数据了. 最关键是搜到一位大神已经破解了该网站的加密解密密钥([c#爬取Silverlight网页](http://blog.csdn.net/kangrydotnet/article/details/43987835)), 才让我能够完成这个原本不可能的任务. 主要步骤包括:

1. 发送post请求, 获取数据(加密); 以及解密后整理数据, 保存为csv文件
1. 由于直接获取的数据经过了加密, 需要反汇编silverlight源代码获取密钥, 解密数据
1. 设置windows计划任务, 每小时重复执行

网站加密之前用python实现了第一步, 每天运行一下就可以拿到当天数据. 由于网站加密以及定时执行的需求, 又增加了另外的步骤.

<!-- PELICAN_END_SUMMARY -->

# 获取数据, 整理数据

因为 [北京空气质量](http://zx.bjmemc.com.cn/) 网站用silverlight实现了前端界面, 不容易直接爬网页得到数据, 比较简单的方法就是直接模拟网页端向服务器请求需要的数据. 这里用wireshark监听网络数据, 刷新一下网页就能抓取到网页端和服务器的交互数据, 经过比较枯燥的对比分析, 定位到关键的post请求包. 这样我们只需要伪造一下这个post请求, 就可以在返回数据中拿到所有数据了. (后来发现用fiddler2软件可以更优雅地完成这一任务= =)

python的网络库可以很方便地实现post请求, 而且这种小脚本用python写起来特别方便. 几十行代码就能把相关数据拿到了, 是一个json字符串(如果没有加密的话).

拿到json数据之后, 用一些正则表达式匹配不同观测点以及观测数据信息, 用字典统计下数据, 就可以整理成表格存进csv文件里了.


# 破解密钥, 解密数据

完全参考 [c#爬取Silverlight网页](http://blog.csdn.net/kangrydotnet/article/details/43987835) 就可以了, 写的非常好.

## C# 调用 python 代码

因为数据爬取和处理都是用python做的, 本来想把上面帖子里的AES解密过程用python实现以下, 但是python的不同编码处理一直是我的痛点, 挣扎很久没有搞定. 查了下用c#调用python比较简单, 所以干脆把python实现的数据爬取和整理整合到c#工程里了.

这部分参考 [C#调用Python脚本并使用Python的第三方模块](http://zh.5long.me/2015/dotnet-call-python/).

## 中文编码问题

一般写代码遇到中文编码处理的问题, 尤其是涉及到网络交互, 都会十分恶心, 这次也不例外. 比较好的解决方法是先把所有编码统一成UTF-8, 比如Visual Studio默认编码是gb2312, 改为UTF-8后再调整一些细节就可以了.


# windows计划任务

参考 [Windows计划任务设置成每小时重复的方法](http://www.htmer.com/article/1039.htm) 中的第一种实现, 可以比较简单地设置按小时执行的计划任务, 每小时调用一次我们的C#工程生成的执行文件.

这里需要注意的一点是在设置"操作"的时候, 需要把"起始于"设置为可执行文件所在路径, 否则虽然任务显示执行成功了, 但其实程序并没有成功运行.